import torch.nn as nn

class Flatten(nn.Module):
    def __init__(self):
        super(Flatten, self).__init__()

    def forward(self, input):
        # input.size(0) 获取了张量 input 的第一个维度的大小，这通常对应于批次大小（batch size）。
        # -1 作为 view 方法的第二个参数，告诉 PyTorch 自动计算这个维度的大小，以保持张量中元素的总数不变。实际上，这意味着将张量的其余维度展平成一个长向量。
        # 总的来说，input.view(input.size(0), -1) 将输入张量 input 重新塑形为一个二维张量，
        # 其中第一个维度是原始的批次大小，第二个维度是展平后的所有特征。这样做常见于将卷积层的输出转换为全连接层的输入。
        return input.view(input.size(0), -1)

class TestNet(nn.Module):
    def __init__(self):
        super(TestNet, self).__init__()
        # 下面是对 nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1) 参数的详细解释：
        #   1: 输入通道数（in_channels）。这表示输入图像（或特征图）的通道数。在处理灰度图像时通常为 1，彩色图像（如RGB图像）为 3。
        #   16: 输出通道数（out_channels）。这是卷积操作后生成的特征图（或称为激活图）的数量。每个输出通道都有一组自己的卷积核，用于从输入中提取不同的特征。
        #   kernel_size=3: 卷积核的大小。这里没有直接在 nn.Conv2d 的括号中看到 kernel_size=3，但根据常规使用和上下文假设，当只提供了输入通道数、输出通道数、步长和填充而没有指定 kernel_size 时，默认的 kernel_size 是 3。卷积核的大小影响了特征提取的范围和效果，3x3 是一个常用的卷积核尺寸。
        #   stride=1: 卷积操作的步长。步长控制着卷积核滑动过输入特征图的速度，stride=1 意味着卷积核每次移动一个像素。
        #   padding=1: 边缘填充。在进行卷积操作之前，为输入数据的边缘添加的零填充的层数。padding=1 表示在输入的每一边上填充 1 层零，这样做通常是为了保持输出特征图的空间尺寸不变（当 stride=1 和 kernel_size=3 时）。

        # nn.MaxPool2d(2, 2) 创建了一个最大池化层， 实现了一个步长为 2、窗口大小为 2x2 的最大池化操作，
        # 这将导致输入特征图在经过这一层之后，其宽度和高度都减少到原来的一半，而深度（即通道数）保持不变。其参数具体含义如下：
        #   第一个参数 2 指的是池化窗口的大小，也就是在每个 2x2 的区域中进行最大池化操作。这意味着在每个 2x2 的局部区域内，只有数值最大的那个元素会被选出来代表这个区域。
        #   第二个参数 2 表示步长（stride），即池化窗口移动的距离。步长为 2 意味着池化窗口每次移动两个像素，这样做的结果是特征图的宽度和高度都会减半，因为每次池化操作都跳过了一个像素。

        # nn.Linear(1*14*14, 10) 创建了一个全连接层，其参数具体含义如下：
        #   1*14*14: 这是输入特征的数量。这里，1*14*14 表示输入向量的维度是 196。这通常意味着你有一个单通道（例如灰度图像）的输入，其空间维度为 14x14 像素，然后被展平成一个 196 维的向量作为全连接层的输入。在卷积神经网络中，这一步通常发生在多个卷积层和池化层之后，当你需要将二维特征图转换为一维特征向量以便进行分类或其他任务时。
        #   10: 这是输出特征的数量，即这个全连接层的神经元数量。在很多情况下，这个数字对应于分类任务中的类别数量。例如，如果你正在构建一个用于手写数字识别（MNIST 数据集）的网络，那么输出大小为 10 可能代表了 10 个数字类别（0 到 9）。
        self.net = nn.Sequential(nn.Conv2d(1, 16, stride=1, padding=1),
                                 nn.MaxPool2d(2,2),
                                 Flatten(),
                                 nn.Linear(1*14*14, 10))

    def forward(self, x):
        return self.net(x)